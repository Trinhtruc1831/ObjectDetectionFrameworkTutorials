{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 90351, done.\u001b[K\n",
      "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
      "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
      "remote: Total 90351 (delta 72), reused 128 (delta 64), pack-reused 90205\u001b[K\n",
      "Receiving objects: 100% (90351/90351), 608.42 MiB | 4.32 MiB/s, done.\n",
      "Resolving deltas: 100% (65087/65087), done.\n"
     ]
    }
   ],
   "source": [
    "!git config --global http.postBuffer 524288000\n",
    "!git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=$PYTHONPATH:/path/to/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting labelImg\n",
      "  Downloading labelImg-1.8.6.tar.gz (247 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyqt5 (from labelImg)\n",
      "  Downloading PyQt5-5.15.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting lxml (from labelImg)\n",
      "  Downloading lxml-5.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Collecting PyQt5-sip<13,>=12.13 (from pyqt5->labelImg)\n",
      "  Downloading PyQt5_sip-12.13.0-cp39-cp39-macosx_10_9_universal2.whl.metadata (504 bytes)\n",
      "Collecting PyQt5-Qt5>=5.15.2 (from pyqt5->labelImg)\n",
      "  Downloading PyQt5_Qt5-5.15.12-py3-none-macosx_11_0_arm64.whl.metadata (536 bytes)\n",
      "Downloading lxml-5.1.0-cp39-cp39-macosx_11_0_arm64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading PyQt5-5.15.10-cp37-abi3-macosx_11_0_arm64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyQt5_Qt5-5.15.12-py3-none-macosx_11_0_arm64.whl (36.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.7/36.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyQt5_sip-12.13.0-cp39-cp39-macosx_10_9_universal2.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: labelImg\n",
      "  Building wheel for labelImg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for labelImg: filename=labelImg-1.8.6-py2.py3-none-any.whl size=261540 sha256=67074b35a7c8a5117f11ea144730c578312f5789f3c6f3fce71f67c4400ccd55\n",
      "  Stored in directory: /Users/trinhtruc/Library/Caches/pip/wheels/a0/2d/29/aaf47d232f5b03ec3e64a8432032f328dfdea1714041712bf6\n",
      "Successfully built labelImg\n",
      "Installing collected packages: PyQt5-Qt5, PyQt5-sip, lxml, pyqt5, labelImg\n",
      "Successfully installed PyQt5-Qt5-5.15.12 PyQt5-sip-12.13.0 labelImg-1.8.6 lxml-5.1.0 pyqt5-5.15.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset\n"
     ]
    }
   ],
   "source": [
    "%cd dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename image file code\n",
    "import os\n",
    "\n",
    "def rename_files(directory):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    t = 1\n",
    "    for file in files:\n",
    "        ext_file = file.split(\".\")[-1]\n",
    "        if (ext_file != \"DS_Store\"):\n",
    "            # Construct the new file name by adding a prefix\n",
    "            new_name = f\"{str(t)}.{ext_file}\"\n",
    "\n",
    "            # # Build the full paths\n",
    "            old_path = os.path.join(directory, file)\n",
    "            new_path = os.path.join(directory, new_name)\n",
    "\n",
    "            # # Rename the file\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f'Renamed: {old_path} to {new_path}')\n",
    "            t = t + 1\n",
    "\n",
    "# Specify the directory and prefix\n",
    "directory_path = './'\n",
    "\n",
    "# Rename files in the specified directory with the given prefix\n",
    "rename_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:/Users/trinhtruc/Downloads/VOCdevkit/CatDog/000001.jpg -> Annotation:/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset/000001.xml\n",
      "Image:/Users/trinhtruc/Downloads/VOCdevkit/CatDog/000011.jpg -> Annotation:/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset/000011.xml\n",
      "Image:/Users/trinhtruc/Downloads/VOCdevkit/CatDog/000018.jpg -> Annotation:/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset/000018.xml\n",
      "Image:/Users/trinhtruc/Downloads/VOCdevkit/CatDog/000108.jpg -> Annotation:/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset/000108.xml\n",
      "Image:/Users/trinhtruc/Downloads/VOCdevkit/CatDog/000157.jpg -> Annotation:/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset/000157.xml\n",
      "Image:/Users/trinhtruc/Downloads/VOCdevkit/CatDog/000205.jpg -> Annotation:/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset/000205.xml\n",
      "Image:/Users/trinhtruc/Downloads/VOCdevkit/CatDog/000517.jpg -> Annotation:/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset/000517.xml\n",
      "Image:/Users/trinhtruc/Downloads/VOCdevkit/CatDog/000533.jpg -> Annotation:/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample/dataset/000533.xml\n"
     ]
    }
   ],
   "source": [
    "!labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import argparse\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "def iterate_dir(source, dest, ratio, copy_xml):\n",
    "    source = source.replace('\\\\', '/')\n",
    "    dest = dest.replace('\\\\', '/')\n",
    "    train_dir = os.path.join(dest, 'train')\n",
    "    test_dir = os.path.join(dest, 'test')\n",
    "\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "\n",
    "    images = [f for f in os.listdir(source)\n",
    "              if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(?i)(.jpg|.jpeg|.png)$', f)]\n",
    "\n",
    "    num_images = len(images)\n",
    "    num_test_images = math.ceil(ratio*num_images)\n",
    "\n",
    "    for i in range(num_test_images):\n",
    "        idx = random.randint(0, len(images)-1)\n",
    "        filename = images[idx]\n",
    "        copyfile(os.path.join(source, filename),\n",
    "                 os.path.join(test_dir, filename))\n",
    "        if copy_xml:\n",
    "            xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "            copyfile(os.path.join(source, xml_filename),\n",
    "                     os.path.join(test_dir,xml_filename))\n",
    "        images.remove(images[idx])\n",
    "\n",
    "    for filename in images:\n",
    "        copyfile(os.path.join(source, filename),\n",
    "                 os.path.join(train_dir, filename))\n",
    "        if copy_xml:\n",
    "            xml_filename = os.path.splitext(filename)[0]+'.xml'\n",
    "            copyfile(os.path.join(source, xml_filename),\n",
    "                     os.path.join(train_dir, xml_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r_/lbw3rw192wl9sx9vtc1c2_xc0000gn/T/ipykernel_44639/4076859984.py:21: DeprecationWarning: Flags not at the start of the expression '([a-zA-Z0-9\\\\s_\\\\\\\\.\\\\-\\\\' (truncated)\n",
      "  if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(?i)(.jpg|.jpeg|.png)$', f)]\n"
     ]
    }
   ],
   "source": [
    "iterate_dir(\"./dataset\", \"./TensorFlow/workspace/training_demo/images\", 0.1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trinhtruc/Documents/STUDY/Khoa học dữ liệu ảnh_Nền tảng và Ứng dụng/230104026_Lab2/ObjectDetectionExample\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_map.pbtxt file created successfully.\n"
     ]
    }
   ],
   "source": [
    "arr_labels = ['cat', 'dog']\n",
    "\n",
    "with open('TensorFlow/workspace/training_demo/annotations/label_map.pbtxt', 'w') as f:\n",
    "    for i, label in enumerate(arr_labels, 1):\n",
    "        f.write(f\"item {{\\n\")\n",
    "        f.write(f\"    id: {i}\\n\")\n",
    "        f.write(f\"    name: '{label}'\\n\")\n",
    "        f.write(f\"}}\\n\\n\")\n",
    "\n",
    "print(\"label_map.pbtxt file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert *.xml to *.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "from collections import namedtuple\n",
    "\n",
    "# Initiate argument parser\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Sample TensorFlow XML-to-TFRecord converter\")\n",
    "parser.add_argument(\"-x\",\n",
    "                    \"--xml_dir\",\n",
    "                    help=\"Path to the folder where the input .xml files are stored.\",\n",
    "                    type=str)\n",
    "parser.add_argument(\"-l\",\n",
    "                    \"--labels_path\",\n",
    "                    help=\"Path to the labels (.pbtxt) file.\", type=str)\n",
    "parser.add_argument(\"-o\",\n",
    "                    \"--output_path\",\n",
    "                    help=\"Path of output TFRecord (.record) file.\", type=str)\n",
    "parser.add_argument(\"-i\",\n",
    "                    \"--image_dir\",\n",
    "                    help=\"Path to the folder where the input image files are stored. \"\n",
    "                         \"Defaults to the same directory as XML_DIR.\",\n",
    "                    type=str, default=None)\n",
    "parser.add_argument(\"-c\",\n",
    "                    \"--csv_path\",\n",
    "                    help=\"Path of output .csv file. If none provided, then no file will be \"\n",
    "                         \"written.\",\n",
    "                    type=str, default=None)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.image_dir is None:\n",
    "    args.image_dir = args.xml_dir\n",
    "\n",
    "label_map = label_map_util.load_labelmap(args.labels_path)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "\n",
    "\n",
    "def xml_to_csv(path):\n",
    "    \"\"\"Iterates through all .xml files (generated by labelImg) in a given directory and combines\n",
    "    them in a single Pandas dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    path : str\n",
    "        The path containing the .xml files\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        The produced dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        filename = root.find('filename').text\n",
    "        width = int(root.find('size').find('width').text)\n",
    "        height = int(root.find('size').find('height').text)\n",
    "        for member in root.findall('object'):\n",
    "            bndbox = member.find('bndbox')\n",
    "            value = (filename,\n",
    "                     width,\n",
    "                     height,\n",
    "                     member.find('name').text,\n",
    "                     int(bndbox.find('xmin').text),\n",
    "                     int(bndbox.find('ymin').text),\n",
    "                     int(bndbox.find('xmax').text),\n",
    "                     int(bndbox.find('ymax').text),\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height',\n",
    "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df\n",
    "\n",
    "\n",
    "def class_text_to_int(row_label):\n",
    "    return label_map_dict[row_label]\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def main(_):\n",
    "\n",
    "    writer = tf.python_io.TFRecordWriter(args.output_path)\n",
    "    path = os.path.join(args.image_dir)\n",
    "    examples = xml_to_csv(args.xml_dir)\n",
    "    grouped = split(examples, 'filename')\n",
    "    for group in grouped:\n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('Successfully created the TFRecord file: {}'.format(args.output_path))\n",
    "    if args.csv_path is not None:\n",
    "        examples.to_csv(args.csv_path, index=None)\n",
    "        print('Successfully created the CSV file: {}'.format(args.csv_path))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Sample TensorFlow XML-to-TFRecord converter\")\n",
    "parser.add_argument(\"-x\",\n",
    "                    \"--xml_dir\",\n",
    "                    help=\"Path to the folder where the input .xml files are stored.\",\n",
    "                    type=str)\n",
    "parser.add_argument(\"-l\",\n",
    "                    \"--labels_path\",\n",
    "                    help=\"Path to the labels (.pbtxt) file.\", type=str)\n",
    "parser.add_argument(\"-o\",\n",
    "                    \"--output_path\",\n",
    "                    help=\"Path of output TFRecord (.record) file.\", type=str)\n",
    "parser.add_argument(\"-i\",\n",
    "                    \"--image_dir\",\n",
    "                    help=\"Path to the folder where the input image files are stored. \"\n",
    "                         \"Defaults to the same directory as XML_DIR.\",\n",
    "                    type=str, default=None)\n",
    "parser.add_argument(\"-c\",\n",
    "                    \"--csv_path\",\n",
    "                    help=\"Path of output .csv file. If none provided, then no file will be \"\n",
    "                         \"written.\",\n",
    "                    type=str, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_xmls_train_path = \"./Tensorflow/workspace/training_demo/images/train\"\n",
    "images_xmls_test_path = \"./Tensorflow/workspace/training_demo/images/test\"\n",
    "output_record_anotation_train_path = \"./Tensorflow/workspace/training_demo/annotations/train.record\"\n",
    "output_record_anotation_test_path = \"./Tensorflow/workspace/training_demo/annotations/test.record\"\n",
    "\n",
    "writer = tf.python_io.TFRecordWriter(args.output_path)\n",
    "path = os.path.join(args.image_dir)\n",
    "examples = xml_to_csv(args.xml_dir)\n",
    "grouped = split(examples, 'filename')\n",
    "for group in grouped:\n",
    "    tf_example = create_tf_example(group, path)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "writer.close()\n",
    "print('Successfully created the TFRecord file: {}'.format(args.output_path))\n",
    "if args.csv_path is not None:\n",
    "    examples.to_csv(args.csv_path, index=None)\n",
    "    print('Successfully created the CSV file: {}'.format(args.csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/train -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/train.record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python generate_tfrecord.py -x \"./Tensorflow/workspace/training_demo/images/train\" -l \"./Tensorflow/workspace/training_demo/annotations/label_map.pbtxt\" -o \"./Documents/Tensorflow/workspace/training_demo/annotations/train.record\"\n",
    "# python generate_tfrecord.py -x \"./Tensorflow/workspace/training_demo/images/test\" -l \"./Tensorflow/workspace/training_demo/annotations/label_map.pbtxt\" -o \"./Documents/Tensorflow/workspace/training_demo/annotations/test.record\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
